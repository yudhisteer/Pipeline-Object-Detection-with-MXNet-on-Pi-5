{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851b41c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd4e72-2f38-4d33-8f02-93f6e201b8c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Set paths\n",
    "base_dir = os.path.join(os.path.dirname(os.getcwd()), 'dataset')\n",
    "train_json_path = os.path.join(base_dir, 'train', 'labels.json')\n",
    "val_json_path = os.path.join(base_dir, 'validation', 'labels.json')\n",
    "train_images_dir = os.path.join(base_dir, 'train', 'data')\n",
    "val_images_dir = os.path.join(base_dir, 'validation', 'data')\n",
    "\n",
    "def load_filtered_annotations(json_path, target_class='Plastic bag'):\n",
    "    \"\"\"Load and filter annotations for only the target class\"\"\"\n",
    "    with open(json_path) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    images = {img['id']: img for img in data['images']}\n",
    "    categories = {cat['id']: cat['name'] for cat in data['categories']}\n",
    "    \n",
    "    records = []\n",
    "    for ann in data['annotations']:\n",
    "        img = images[ann['image_id']]\n",
    "        class_name = categories[ann['category_id']]\n",
    "        \n",
    "        if class_name == target_class: \n",
    "            records.append({\n",
    "                'ImageID': Path(img['file_name']).stem,\n",
    "                'LabelName': '/m/05gqfk',\n",
    "                'XMin': ann['bbox'][0] / img['width'],\n",
    "                'YMin': ann['bbox'][1] / img['height'],\n",
    "                'XMax': (ann['bbox'][0] + ann['bbox'][2]) / img['width'],\n",
    "                'YMax': (ann['bbox'][1] + ann['bbox'][3]) / img['height']\n",
    "            })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Load only plastic bag annotations\n",
    "print(f\"Loading training data from: {train_json_path}\")\n",
    "df_train = load_filtered_annotations(train_json_path)\n",
    "print(f\"Loading validation data from: {val_json_path}\")\n",
    "df_validation = load_filtered_annotations(val_json_path)\n",
    "\n",
    "# Update paths for the notebook\n",
    "data_path_validation = os.path.join(val_images_dir, '*.jpg')\n",
    "data_path_train = os.path.join(train_images_dir, '*.jpg')\n",
    "validation_images_path = val_images_dir\n",
    "train_images_path = train_images_dir\n",
    "\n",
    "# Verify\n",
    "print(\"\\nFiltered Data loaded successfully!\")\n",
    "print(f\"Found {len(df_train)} plastic bag training instances\")\n",
    "print(f\"Found {len(df_validation)} plastic bag validation instances\")\n",
    "print(\"\\nSample training data:\")\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cc3d29-b1c7-41c4-83af-adbab93efb54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5849b80-3f6c-49e7-bbaf-06b582b9f40e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602fb08e-c4f6-4485-9d25-fbe3dad221f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "counter = 0\n",
    "\n",
    "img_paths = data_path_train\n",
    "folder = glob.glob(img_paths)\n",
    "\n",
    "for i in folder:\n",
    "    counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbf941a-394f-42aa-9a10-6579f55680cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "counter = 0\n",
    "\n",
    "img_paths = data_path_validation\n",
    "folder = glob.glob(img_paths)\n",
    "\n",
    "for i in folder:\n",
    "    counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb86479-e854-4dc3-a25c-df8eeb493944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "\n",
    "train_list_ids = []\n",
    "validation_list_ids = []\n",
    "\n",
    "def get_ids(split, print_this, to_append_list):\n",
    "    try:\n",
    "        if split == data_path_train:\n",
    "            folder = glob.glob(data_path_train)\n",
    "            img_ids = [Path(f).stem for f in folder]\n",
    "        elif split == data_path_validation:\n",
    "            folder = glob.glob(data_path_validation)\n",
    "            img_ids = [Path(f).stem for f in folder]\n",
    "        else:\n",
    "            raise Exception(\"Invalid Parameter\")\n",
    "        \n",
    "        if not img_ids:\n",
    "            print(f\"Warning: No images found in {split}\")\n",
    "        \n",
    "        to_append_list.extend(img_ids)\n",
    "        print(f\"Found {len(img_ids)} images in {split}\")\n",
    "        print(print_this)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error in get_ids: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Clear and reinitialize lists\n",
    "train_list_ids = []\n",
    "validation_list_ids = []\n",
    "\n",
    "# Run with debugging\n",
    "print(\"\\nProcessing training images:\")\n",
    "success_train = get_ids(data_path_train, \"Finished training images\", train_list_ids)\n",
    "\n",
    "print(\"\\nProcessing validation images:\")\n",
    "success_val = get_ids(data_path_validation, \"Finished validation images\", validation_list_ids)\n",
    "\n",
    "# Verify results\n",
    "if success_train and train_list_ids:\n",
    "    print(f\"\\nFirst training ID: {train_list_ids[0]}\")\n",
    "else:\n",
    "    print(\"Failed to get training IDs\")\n",
    "\n",
    "if success_val and validation_list_ids:\n",
    "    print(f\"First validation ID: {validation_list_ids[0]}\")\n",
    "else:\n",
    "    print(\"Failed to get validation IDs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77ac9e5-0e6a-4421-8681-7204f5974a78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_ids(data_path_train, \"I finished the task\", train_list_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550335a-4585-49a9-86e7-990893ebd359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_list_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5923d381-6698-4ecd-8022-a8b0c6d58396",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_ids(data_path_validation, \"I finished the task\", validation_list_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e731a3-49e1-415d-81e4-9e46572fdada",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_list_ids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa84de0-5208-46e9-a83e-c31fb485cb75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and analyze class information from JSON annotations\n",
    "def get_class_info(json_path):\n",
    "    with open(json_path) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Get all categories\n",
    "    categories = {cat['id']: cat['name'] for cat in data['categories']}\n",
    "    \n",
    "    # Count occurrences of each class\n",
    "    class_counts = {}\n",
    "    for ann in data['annotations']:\n",
    "        class_name = categories[ann['category_id']]\n",
    "        class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'className': list(categories.values()),\n",
    "        'Object': list(categories.values()),  # Duplicate for compatibility\n",
    "        'Count': [class_counts.get(name, 0) for name in categories.values()]\n",
    "    })\n",
    "\n",
    "# Get class information for both datasets\n",
    "train_classes_df = get_class_info(train_json_path)\n",
    "validation_classes_df = get_class_info(val_json_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2177f074-a306-45ad-9285-8d4a0af885eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter for plastic bags (case insensitive)\n",
    "plastic_bag_names = ['plastic bag', 'Plastic bag', 'plastic_bag']  # Common variations\n",
    "train_identifer = train_classes_df[train_classes_df['className'].str.lower().isin([name.lower() for name in plastic_bag_names])]\n",
    "validation_identifer = validation_classes_df[validation_classes_df['className'].str.lower().isin([name.lower() for name in plastic_bag_names])]\n",
    "\n",
    "print(\"Training set class information:\")\n",
    "print(train_classes_df)\n",
    "print(\"\\nPlastic bags in training set:\")\n",
    "print(train_identifer)\n",
    "print('-'*40)\n",
    "print(\"Validation set class information:\")\n",
    "print(validation_classes_df)\n",
    "print(\"\\nPlastic bags in validation set:\")\n",
    "print(validation_identifer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0cab3f-f761-4174-b322-b1d2e8227585",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_row_from_df(split):\n",
    "    dataframe = \"\"\n",
    "    \n",
    "    if split == \"train\":\n",
    "        dataframe,ids_to_check = df_train, train_list_ids#517\n",
    "    elif split == \"validation\":\n",
    "        dataframe,ids_to_check = df_validation, validation_list_ids#9\n",
    "    else:\n",
    "        raise Exception(\"Invalid parameter, must be either train or validation\")\n",
    "    \n",
    "    img_ids_len = len(ids_to_check)\n",
    "    rand = random.randint(0,img_ids_len-1)\n",
    "    id = ids_to_check[rand]\n",
    "    print(id)\n",
    "    r = dataframe.loc[(dataframe.ImageID == id) & (dataframe.LabelName == '/m/05gqfk')]\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364afb7e-61b5-4ddc-8ea0-936e32c7abb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_row_from_df(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521fd2ef-6fa7-4bb6-93df-f418c46dacaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "def visualize_random_image(split):\n",
    "    if split == 'train':\n",
    "        images_path = train_images_path\n",
    "    elif split == 'validation':\n",
    "        images_path = validation_images_path\n",
    "    else:\n",
    "        raise Exception(\"Invalid input parameter, must be either train or validation\")\n",
    "    \n",
    "    images_paths = glob.glob(os.path.join(images_path, '*.jpg'))\n",
    "    random_image = random.choice(images_paths)\n",
    "    img = mpimg.imread(random_image)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    plt.title(f\"Random {split} image: {Path(random_image).name}\")\n",
    "    plt.show()\n",
    "\n",
    "visualize_random_image(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cd69cd-8af8-4741-8134-d84f9c78a530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def visualize_many(from_num, to_num, dataset):\n",
    "    \"\"\"Visualize multiple images\"\"\"\n",
    "    if dataset == 'train':\n",
    "        image_ids = train_list_ids\n",
    "        base_path = data_path_train.replace('*.jpg', '')\n",
    "    elif dataset == 'validation':\n",
    "        image_ids = validation_list_ids\n",
    "        base_path = data_path_validation.replace('*.jpg', '')\n",
    "    else:\n",
    "        raise ValueError(\"Dataset must be 'train' or 'validation'\")\n",
    "    \n",
    "    total_images = len(image_ids)\n",
    "    print(f\"\\nVisualizing {dataset} set (has {total_images} total images)\")\n",
    "    \n",
    "    # Validate requested range\n",
    "    if from_num >= total_images:\n",
    "        print(f\"Start number {from_num} >= total images {total_images}\")\n",
    "        return\n",
    "    to_num = min(to_num, total_images)\n",
    "    \n",
    "    # Calculate grid layout\n",
    "    num_images = to_num - from_num\n",
    "    columns = 4\n",
    "    rows = (num_images + columns - 1) // columns\n",
    "    \n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(15, 5*rows))\n",
    "    plt.suptitle(f\"{dataset.capitalize()} Images {from_num}-{to_num-1}\", y=1.02)\n",
    "    \n",
    "    # Display images\n",
    "    for i in range(from_num, to_num):\n",
    "        try:\n",
    "            img_id = image_ids[i]\n",
    "            img_path = os.path.join(base_path, f\"{img_id}.jpg\")\n",
    "            \n",
    "            if not os.path.exists(img_path):\n",
    "                print(f\"Image not found: {img_path}\")\n",
    "                continue\n",
    "                \n",
    "            img = mpimg.imread(img_path)\n",
    "            ax = fig.add_subplot(rows, columns, i-from_num+1)\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(f\"ID: {img_id}\")\n",
    "            ax.axis('off')\n",
    "            \n",
    "            # Add bounding boxes if available\n",
    "            if dataset == 'train':\n",
    "                boxes = df_train[df_train['ImageID'] == img_id]\n",
    "            else:\n",
    "                boxes = df_validation[df_validation['ImageID'] == img_id]\n",
    "                \n",
    "            for _, row in boxes.iterrows():\n",
    "                xmin = row['XMin'] * img.shape[1]\n",
    "                xmax = row['XMax'] * img.shape[1]\n",
    "                ymin = row['YMin'] * img.shape[0]\n",
    "                ymax = row['YMax'] * img.shape[0]\n",
    "                \n",
    "                rect = plt.Rectangle(\n",
    "                    (xmin, ymin), xmax-xmin, ymax-ymin,\n",
    "                    linewidth=1, edgecolor='r', facecolor='none'\n",
    "                )\n",
    "                ax.add_patch(rect)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {i}: {str(e)}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "print(\"=== Training Images ===\")\n",
    "visualize_many(0, 8, \"train\")  # Show first 8 training images\n",
    "\n",
    "print(\"\\n=== Validation Images ===\")\n",
    "visualize_many(0, 6, \"validation\")  # Show first 6 validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed98eed-25cb-4a37-9e1e-df3815b6d0de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_validation.loc[(df_validation['ImageID'] == 'ecd5fc22a65b8d32') & (df_validation.LabelName == '/m/05gqfk')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839a460a-e8c4-4b9d-af74-6de7bbc00c7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Use the first available image from the training set\n",
    "if train_list_ids:\n",
    "    image_id = train_list_ids[0]  # Get first training image ID\n",
    "    image_path = os.path.join(data_path_train.replace('*.jpg', ''), f\"{image_id}.jpg\")\n",
    "    \n",
    "    # Open and display the image\n",
    "    im = Image.open(image_path)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(im)\n",
    "    \n",
    "    # Print image info\n",
    "    image_width, image_height = im.size\n",
    "    print(f\"Image: {image_path}\")\n",
    "    print(f\"Dimensions: {image_width} x {image_height}\")\n",
    "    \n",
    "    # Example bounding box coordinates (normalized)\n",
    "    xmin, ymin = 0.377083, 0.778125  # Normalized coordinates\n",
    "    xmax, ymax = 0.745833, 0.96875\n",
    "    \n",
    "    # Convert to pixel coordinates\n",
    "    xmin_px = xmin * image_width\n",
    "    xmax_px = xmax * image_width\n",
    "    ymin_px = ymin * image_height\n",
    "    ymax_px = ymax * image_height\n",
    "    \n",
    "    # Draw the bounding box\n",
    "    rect = patches.Rectangle(\n",
    "        (xmin_px, ymin_px), \n",
    "        xmax_px - xmin_px,  # width\n",
    "        ymax_px - ymin_px,  # height\n",
    "        linewidth=2, \n",
    "        edgecolor='red', \n",
    "        facecolor='none'\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    plt.title(f\"Bounding Box Example\\nImage ID: {image_id}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No training images found. Please check your data_path_train and train_list_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d98396-b256-41fe-b0f5-88efaccd983f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "import glob\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "def visualize_bb(dataset):\n",
    "    images_path = train_images_path if dataset == 'train' else validation_images_path if dataset == 'validation' else 0\n",
    "    if images_path == 0:\n",
    "        raise Exception(\"Invalid input parameter, must be either train or validation\")\n",
    "    \n",
    "    # Add pattern for glob\n",
    "    image_folder = os.path.join(images_path, '*.jpg')\n",
    "    images_paths = glob.glob(image_folder)\n",
    "    num_of_images = len(images_paths)\n",
    "    if num_of_images == 0:\n",
    "        raise ValueError(f\"No images found in {images_path}. Check path and files.\")\n",
    "    \n",
    "    random_int = random.randint(0, num_of_images -1)\n",
    "    random_image = images_paths[random_int]\n",
    "    #print(random_image)\n",
    "    img = Image.open(random_image)\n",
    "    id_of_image = Path(random_image).stem  # Use stem for ID (no slicing)\n",
    "    \n",
    "    df = df_train if dataset == 'train' else df_validation\n",
    "    df_rows = df.loc[(df.ImageID == id_of_image) & (df.LabelName == '/m/05gqfk')]\n",
    "    \n",
    "    image_width, image_height = img.size\n",
    "    \n",
    "    fig ,ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    \n",
    "    for index, row in df_rows.iterrows():\n",
    "        print(row['XMin'], row['XMax'], row['YMin'], row['YMax'])\n",
    "        \n",
    "        xmin = row['XMin']\n",
    "        xmax = row['XMax']\n",
    "        ymin = row['YMin']\n",
    "        ymax = row['YMax']\n",
    "        \n",
    "        new_xmin = xmin * image_width\n",
    "        new_xmax = xmax * image_width\n",
    "        new_ymin = ymin * image_height\n",
    "        new_ymax = ymax * image_height\n",
    "        print(new_xmin,new_xmax,new_ymin,new_ymax)\n",
    "        \n",
    "        \n",
    "        width = new_xmax - new_xmin\n",
    "        height = new_ymax - new_ymin\n",
    "        \n",
    "        rect = patches.Rectangle((new_xmin,new_ymin), width, height, linewidth = 1, edgecolor = 'r', facecolor = 'none')\n",
    "        ax.add_patch(rect)\n",
    "    plt.show()\n",
    "    \n",
    "visualize_bb(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcc7c92-be57-44f1-b2f5-1fab7717218a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(df_train))\n",
    "print(len(df_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175d24fa-6401-4417-9af1-0b0e5b4810ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_dataframe(df_for_train, df_for_validation):\n",
    "    # Debug: Check DataFrame content\n",
    "    print(\"df_train LabelName unique:\", df_for_train['LabelName'].unique())\n",
    "    print(\"df_validation LabelName unique:\", df_for_validation['LabelName'].unique())\n",
    "    print(f\"Before processing: len(df_train) = {len(df_for_train)}, len(df_validation) = {len(df_for_validation)}\")\n",
    "    \n",
    "    # No filtering needed since all rows are '/m/05gqfk'\n",
    "    df_train_cleansed = df_for_train\n",
    "    df_validation_cleansed = df_for_validation\n",
    "    \n",
    "    print(f\"After processing: len(df_train_cleansed) = {len(df_train_cleansed)}, len(df_validation_cleansed) = {len(df_validation_cleansed)}\")\n",
    "    return df_train_cleansed, df_validation_cleansed\n",
    "\n",
    "df_train_cleansed, df_validation_cleansed = clean_dataframe(df_train, df_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd77bf6e-c3aa-404f-9dfb-b31edb9ad23e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df_train_cleansed)\n",
    "\n",
    "#We have 517 train images, but some of those images have multiple bb, and the 986 is the number\n",
    "#of rows we have in our new df_train_cleansed, and each row represents one bbounding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a68e820-7bac-4d76-873e-e189d4b44584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "986/517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d758c28d-0f57-4939-83a9-114cdef57b86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df_validation_cleansed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e4c13d-d4f3-4637-a0e5-c6073a9db9b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_validation_cleansed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32b0e39-f7f2-4dc0-9fcd-7d6d2c3f2435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_cleansed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8542f7-b7ab-41a4-88b1-e742d42d430a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train, test = train_test_split(df_train_cleansed, test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6119d249-8278-414d-8413-0830e7d90497",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d535161-1076-4b05-bded-eefa86218b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848bcfd5-806c-4ad4-9b40-f26f1b720ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "788 + 198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c78f42-2472-4ba3-8e0b-96fdbc5e8f75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"001.Plastic_bag/images/train\", exist_ok=True)\n",
    "os.makedirs(\"001.Plastic_bag/images/test\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecb8685-5aba-4042-b7d1-2e30dc16ec7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ids = test[\"ImageID\"].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b4a8b1-34be-4c29-86c9-8b076b0429de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57c7f07-d86e-42d8-b977-9ec131585e86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ids = train[\"ImageID\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311874e4-97f9-42ae-b9e5-fa1fe2ba5a1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3007526-0743-4360-ab66-461fbb4f2966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Dynamically set base_dir\n",
    "base_dir = os.path.join(os.path.dirname(os.getcwd()), 'dataset')\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(os.path.join(base_dir, '001.Plastic_bag/images/train'), exist_ok=True)\n",
    "os.makedirs(os.path.join(base_dir, '001.Plastic_bag/images/test'), exist_ok=True)\n",
    "\n",
    "# Move/copy images for test\n",
    "to_loop = os.path.join(base_dir, 'train/data/*.jpg')\n",
    "folder = glob.glob(to_loop)\n",
    "new_path_test = os.path.join(base_dir, '001.Plastic_bag/images/test')\n",
    "\n",
    "for path in folder:\n",
    "    id = Path(path).stem\n",
    "    if id in test_ids:\n",
    "        if id in train_ids:\n",
    "            shutil.copy(path, f\"{new_path_test}/{id}.jpg\")\n",
    "        else:\n",
    "            shutil.copy(path, f\"{new_path_test}/{id}.jpg\")  # Copy to preserve source\n",
    "\n",
    "# Move/copy images for train\n",
    "new_path_train = os.path.join(base_dir, '001.Plastic_bag/images/train')\n",
    "for path in folder:\n",
    "    id = Path(path).stem\n",
    "    if id in train_ids:\n",
    "        shutil.copy(path, f\"{new_path_train}/{id}.jpg\")\n",
    "\n",
    "# Ensure final_train_df and final_test_df are defined\n",
    "final_train_df = train.copy()\n",
    "final_test_df = test.copy()\n",
    "\n",
    "# Update ImagePath in final_train_df and final_test_df\n",
    "final_train_df['ImageID'] = final_train_df['ImagePath'].apply(lambda x: Path(x).stem)\n",
    "final_test_df['ImageID'] = final_test_df['ImagePath'].apply(lambda x: Path(x).stem)\n",
    "final_train_df['ImagePath'] = final_train_df['ImageID'].apply(lambda x: f\"001.Plastic_bag/images/train/{x}.jpg\")\n",
    "final_test_df['ImagePath'] = final_test_df['ImageID'].apply(lambda x: f\"001.Plastic_bag/images/test/{x}.jpg\")\n",
    "\n",
    "# Debug\n",
    "print(\"Updated final_train_df ImagePath:\", final_train_df['ImagePath'].unique())\n",
    "print(\"Updated final_test_df ImagePath:\", final_test_df['ImagePath'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6c459a-bf1f-4329-8694-f27e4bbc5cfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count images in test\n",
    "path_to_test = os.path.join(base_dir, '001.Plastic_bag/images/test/*.jpg')\n",
    "folder = glob.glob(path_to_test)\n",
    "counter = 0\n",
    "for i in folder:\n",
    "    counter += 1\n",
    "print(\"Test images count:\", counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9710ca4a-5820-46b0-b7fe-34c3880570ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count images in train\n",
    "path_to_train = os.path.join(base_dir, '001.Plastic_bag/images/train/*.jpg')\n",
    "folder = glob.glob(path_to_train)\n",
    "counter = 0\n",
    "for i in folder:\n",
    "    counter += 1\n",
    "print(\"Train images count:\", counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3b9dd6-bec2-4bc0-8fd9-83ff11ba2930",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#orignally we had 517 images, but because some of them are needed in both the train and test we now\n",
    "#have a total of 449 + 162 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb12618-7d87-42c8-9023-6e9a398a43dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "449 + 162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931cc03f-96a9-45bd-9f99-40879c24bf61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "611 - 517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcebe74-412c-4f37-b29f-07d6b84098ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "test_image_ids = []\n",
    "test_folder = glob.glob('001.Plastic_bag/images/test/*.jpg')\n",
    "\n",
    "for i in test_folder:\n",
    "    id = Path(i).stem\n",
    "    test_image_ids.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51471fe5-c539-4189-af6c-0a8520601e9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(test_image_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2ba9f1-2461-4efc-9a2c-9058c267cf3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_image_ids = []\n",
    "train_folder = glob.glob('001.Plastic_bag/images/train/*.jpg')\n",
    "\n",
    "for i in train_folder:\n",
    "    id = Path(i).stem\n",
    "    train_image_ids.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1a6354-c734-4f27-b47c-206d63ef4a90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(train_image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31665445-d3b7-4365-9713-67b75dcdb134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ids = final_train_df['ImagePath'].tolist()\n",
    "test_ids = final_test_df['ImagePath'].tolist()\n",
    "\n",
    "print(\"train_ids:\", train_ids)\n",
    "print(\"test_ids:\", test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2292ef-5c1b-4c10-8c91-19ef3b48a59d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(train_df_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d391d4-b6ae-4d11-bb9c-478e6b752383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(test_df_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b5cf5-8b34-4f67-b192-1143ef554e50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_both = set(train_df_ids).intersection(train_image_ids)\n",
    "len(train_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b234ea-0931-4a6c-bd89-abb2f6912d5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_both = set(test_df_ids).intersection(test_image_ids)\n",
    "len(test_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d74375-1339-477b-aff6-fe22c03b7496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 222 2 5 0.000 0.4 0.3 0.9 0.44  path/to/image11.jpg\n",
    "# 222 2 5 0.000 0.5 0.2 0.33 0.8 path/to/image11.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c09828-bca9-4f11-acf9-7dcfc227aecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#index header_column label_width className xmin ymin xmax ymax path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33ac8f7-36a4-4f25-8134-89063d0a2a80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = train.copy()\n",
    "test_df = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d60c40f-5311-40d0-aa33-b48628e5922f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.rename(columns = {\"LabelName\": \"className\"}, inplace = True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2f4ee6-78e5-4a5c-bdee-769d326980da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.rename(columns = {\"LabelName\": \"className\"}, inplace = True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bf1f47-44a3-4add-b327-12f554a54c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(train_df))#788"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f86c287-08e2-428b-8d8c-3410705302ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(test_df))# 198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c311dd18-e82d-4cc9-a9c7-d6a20ecaeca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df[\"header_cols\"] = 2\n",
    "train_df[\"label_width\"] = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f262ad-74a0-44da-9388-8660a8834d55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ecedcd-aa93-43b8-b859-44eee24b662b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df[\"header_cols\"] = 2\n",
    "test_df[\"label_width\"] = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c092b7-621c-49bb-b0dd-ac051a775f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71f274e-84e2-4448-aa5c-076d41a36f17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df[\"ImagePath\"] = \"001.Plastic_bag/images/train/\"+train_df['ImageID']+ '.jpg'\n",
    "test_df[\"ImagePath\"] = \"001.Plastic_bag/images/test/\"+test_df['ImageID']+ '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c034af-24d2-486c-bfaf-a575b4107bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465fd08f-3b20-4506-91dc-3f48be7d8960",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a898bf4-a649-41ce-b0d9-88af457fe0ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = train_df[['header_cols', 'label_width', 'className', 'XMin', 'YMin', 'XMax', 'YMax', 'ImagePath']]\n",
    "test_df = test_df[['header_cols', 'label_width', 'className', 'XMin', 'YMin', 'XMax', 'YMax', 'ImagePath']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca55bfb2-2d76-44e0-ba3d-4876534c635d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae7bf47-900b-4da1-b66c-46002ab57be6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.precision\",4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679edfdb-701b-4f24-87ab-fb0cced1356f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_train_df = train_df.copy()\n",
    "final_train_df['className'] = \"0.000\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb19050-d26e-4fef-b6ed-cd3a3266780f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f2e816-b792-4891-884e-29ff9dcba218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_test_df = test_df.copy()\n",
    "final_test_df['className'] = \"0.000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ba4fda-6907-43b4-af4f-2cdc3bd4ea29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c065f54-ce5e-431a-8022-5a7ed45b18da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Move 'train.lst' and 'test.lst' to '001.Plastic_bag/' (create if needed)\n",
    "os.makedirs('001.Plastic_bag', exist_ok=True)\n",
    "\n",
    "if os.path.exists('train.lst'):\n",
    "    shutil.move('train.lst', os.path.join('001.Plastic_bag', 'train.lst'))\n",
    "else:\n",
    "    print(\"train.lst not found, skipping move\")\n",
    "\n",
    "if os.path.exists('test.lst'):\n",
    "    shutil.move('test.lst', os.path.join('001.Plastic_bag', 'test.lst'))\n",
    "else:\n",
    "    print(\"test.lst not found, skipping move\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f79f6c-8198-4548-a9b6-93a475d2d7dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "folder = glob.glob('001.Plastic_bag/images/test/*.jpg')\n",
    "count = 0\n",
    "for i in folder:\n",
    "    count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa1acc-e31d-4f1a-bccf-38878d7ef4b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ids = final_test_df['ImagePath'].tolist()\n",
    "print(len(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82caf13-d90f-4b59-80ca-3968b8542309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_path = test_ids[0] if test_ids else ''\n",
    "df_row = final_test_df.loc[final_test_df['ImagePath'] == image_path ]\n",
    "df_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c3fcd9-7923-429a-b0ac-fbd1ba63ca6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "final = []\n",
    "idx = 0  # Sequential index\n",
    "for id in test_ids:\n",
    "    \n",
    "    df_rows = final_test_df.loc[final_test_df['ImagePath'] == id ]\n",
    "    \n",
    "    length = len(df_rows)\n",
    "    count = 1\n",
    "    arr = [idx, 2, 5]\n",
    "    \n",
    "    for index,row in df_rows.iterrows():\n",
    "        xmin = str(row['XMin'])\n",
    "        ymin = str(row['YMin'])\n",
    "        xmax = str(row['XMax'])\n",
    "        ymax = str(row['YMax'])\n",
    "        \n",
    "        arr.extend([\"0.000\", xmin, ymin, xmax, ymax])\n",
    "        \n",
    "        if count == length:\n",
    "            arr.append(f\"test/{Path(id).stem}.jpg\")  # Relative path\n",
    "        count+=1\n",
    "        \n",
    "        \n",
    "    final.append(arr)\n",
    "    idx += 1\n",
    "    \n",
    "    \n",
    "with open('test.lst', 'w', newline = '') as out:\n",
    "    for row in final:\n",
    "        writer = csv.writer(out, delimiter = '\\t')\n",
    "        writer.writerow(row)\n",
    "        \n",
    "final_test_df[final_test_df['ImagePath'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42804ca5-bb19-4cff-9449-2999528a6ef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "final_test_df[final_test_df['ImagePath'] == test_ids[0] if test_ids else '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1284644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "final = []\n",
    "idx = 0  # Sequential index\n",
    "for id in train_ids:\n",
    "    \n",
    "    df_rows = final_train_df.loc[final_train_df['ImagePath'] == id ]\n",
    "    \n",
    "    length = len(df_rows)\n",
    "    count = 1\n",
    "    arr = [idx, 2, 5]\n",
    "    \n",
    "    for index,row in df_rows.iterrows():\n",
    "        xmin = str(row['XMin'])\n",
    "        ymin = str(row['YMin'])\n",
    "        xmax = str(row['XMax'])\n",
    "        ymax = str(row['YMax'])\n",
    "        \n",
    "        arr.extend([\"0.000\", xmin, ymin, xmax, ymax])\n",
    "        \n",
    "        if count == length:\n",
    "            arr.append(f\"train/{Path(id).stem}.jpg\")  # Relative path\n",
    "        count+=1\n",
    "        \n",
    "        \n",
    "    final.append(arr)\n",
    "    idx += 1\n",
    "    \n",
    "    \n",
    "with open('train.lst', 'w', newline = '') as out:\n",
    "    for row in final:\n",
    "        writer = csv.writer(out, delimiter = '\\t')\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b6a3de-3645-45be-9378-c9320fac0c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Theory Lesson\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "im = Image.open(os.path.join(train_images_dir, '029cf7b6d1a98a8c.jpg'))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(im)\n",
    "\n",
    "image_width, image_height = im.size\n",
    "print(image_width, image_height) # 768 1024\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xmin = 0.0 * image_width\n",
    "xmax = 0.9968 * image_width\n",
    "ymin = 0.1 * image_height\n",
    "ymax = 0.7339 * image_height\n",
    "\n",
    "\n",
    "width = xmax - xmin\n",
    "height = ymax - ymin\n",
    "\n",
    "rect = patches.Rectangle((xmin,ymin), width, height, linewidth = 1, edgecolor = 'r', facecolor = 'none')\n",
    "\n",
    "\n",
    "ax.add_patch(rect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac833a0-e1b0-402f-a39a-6d9577ed6904",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Theory Lesson\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "# Use a valid image path from dataset (replace with actual if needed)\n",
    "im = Image.open(os.path.join(train_images_dir, '004bd64410736c69.jpg'))\n",
    "im = im.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(im)\n",
    "\n",
    "image_width, image_height = im.size\n",
    "print(image_width, image_height) # Expected: 1024 683 (adjusted for your image)\n",
    "\n",
    "# Sample normalized coords from JSON for this image (flipped Plastic bag)\n",
    "xmin_flipped_norm = 1 - 0.6611  # Flipped from original xmax_norm\n",
    "xmax_flipped_norm = 1 - 0.2328  # Flipped from original xmin_norm\n",
    "ymin_norm = 0.1186\n",
    "ymax_norm = 0.7358\n",
    "\n",
    "xmin = xmin_flipped_norm * image_width\n",
    "xmax = xmax_flipped_norm * image_width\n",
    "ymin = ymin_norm * image_height\n",
    "ymax = ymax_norm * image_height\n",
    "\n",
    "\n",
    "  \n",
    "width = xmax - xmin\n",
    "height = ymax - ymin\n",
    "\n",
    "rect = patches.Rectangle((xmin, ymin), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "\n",
    "  # Add the patch to the Axes\n",
    "ax.add_patch(rect)\n",
    "\n",
    "\n",
    "  # Display the image\n",
    "ax.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3eff82-1392-4f52-bfa5-e6e681a1201c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.move('','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98ec3fb-16ed-49bc-95e0-7a83662c96de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "import glob\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Update paths to point to dataset/001.Plastic_bag/\n",
    "base_dir = os.path.join(os.path.dirname(os.getcwd()), 'dataset')\n",
    "test_images_path = os.path.join(base_dir, '001.Plastic_bag/images/test')  # Directory path\n",
    "train_images_path = os.path.join(base_dir, '001.Plastic_bag/images/train')  # Directory path\n",
    "\n",
    "# Debug: Check if images exist\n",
    "print(\"Train images:\", os.listdir(train_images_path))\n",
    "print(\"Test images:\", os.listdir(test_images_path))\n",
    "\n",
    "def visualize_transposed_bb(dataset):\n",
    "    images_path = train_images_path if dataset == 'train' else test_images_path if dataset == 'test' else 0\n",
    "    if images_path == 0:\n",
    "        raise Exception(\"Invalid input parameter, must be either train or test\")\n",
    "    \n",
    "    # Add glob pattern for images\n",
    "    image_folder = os.path.join(images_path, '*.jpg')\n",
    "    images_paths = glob.glob(image_folder)\n",
    "    num_of_images = len(images_paths)\n",
    "    if num_of_images == 0:\n",
    "        raise ValueError(f\"No images found in {images_path}. Check path and files.\")\n",
    "    \n",
    "    random_int = random.randint(0, num_of_images - 1)\n",
    "    random_image = images_paths[random_int]\n",
    "    print(random_image)\n",
    "    img = Image.open(random_image)\n",
    "    img = img.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "    id_of_image = Path(random_image).stem  # Use stem for ID\n",
    "    \n",
    "    df = final_train_df if dataset == 'train' else final_test_df\n",
    "    # Update filter to match ImagePath format in final_*_df\n",
    "    df_rows = df.loc[(df['ImagePath'] == f\"dataset/001.Plastic_bag/images/{dataset}/{id_of_image}.jpg\") & (df['className'] == '0.000')]\n",
    "    \n",
    "    image_width, image_height = img.size\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    for index, row in df_rows.iterrows():\n",
    "        print(row['XMin'], row['XMax'], row['YMin'], row['YMax'])\n",
    "        \n",
    "        xmin = row['XMin']\n",
    "        xmax = row['XMax']\n",
    "        ymin = row['YMin']\n",
    "        ymax = row['YMax']\n",
    "        \n",
    "        new_xmin = xmin * image_width\n",
    "        new_xmax = xmax * image_width\n",
    "        new_ymin = ymin * image_height\n",
    "        new_ymax = ymax * image_height\n",
    "        print(new_xmin, new_xmax, new_ymin, new_ymax)\n",
    "        \n",
    "        # Flip the bb coordinates\n",
    "        xmax_flipped = (image_width/2) - (new_xmin-(image_width/2))\n",
    "        xmin_flipped = (image_width/2) - (new_xmax-(image_width/2))\n",
    "        \n",
    "        width = xmax_flipped - xmin_flipped\n",
    "        height = new_ymax - new_ymin\n",
    "        \n",
    "        rect = patches.Rectangle((xmin_flipped, new_ymin), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    plt.show()\n",
    "    \n",
    "visualize_transposed_bb(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13b1c13-0ebc-4252-a9a8-162996e63cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(final_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494168db-1f5e-4953-9a4a-466e6c6bc7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Update paths to point to dataset/001.Plastic_bag/\n",
    "base_dir = os.path.join(os.path.dirname(os.getcwd()), 'dataset')\n",
    "test_images_path = os.path.join(base_dir, '001.Plastic_bag/images/test')  # Directory path\n",
    "train_images_path = os.path.join(base_dir, '001.Plastic_bag/images/train')  # Directory path\n",
    "\n",
    "# Debug: Check if images exist\n",
    "print(\"Train images:\", os.listdir(train_images_path))\n",
    "print(\"Test images:\", os.listdir(test_images_path))\n",
    "\n",
    "def augment_data(dataset):\n",
    "    images_path = train_images_path if dataset == \"train\" else test_images_path if dataset == \"test\" else 0\n",
    "    if images_path == 0:\n",
    "        raise Exception(\"Invalid Input parameter\")\n",
    "    \n",
    "    df = final_train_df if dataset == \"train\" else final_test_df\n",
    "    \n",
    "    temp_df = pd.DataFrame(columns=[\"header_cols\",\"label_width\",\"className\",\"XMin\",\"YMin\",\"XMax\",\"YMax\",\"ImagePath\"], dtype=object)\n",
    "    counter = 0\n",
    "    for index, row in df.iterrows():\n",
    "        img_path = row[\"ImagePath\"]  # Image path in the df\n",
    "        id = Path(img_path).stem  # Use stem for ID\n",
    "        im_path = os.path.join(images_path, f\"{id}.jpg\")  # Full image path\n",
    "        img = Image.open(im_path)\n",
    "        image_width, image_height = img.size\n",
    "        img_flip = img.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "        img_flip.save(os.path.join(images_path, f\"flipped_{id}.jpg\"))\n",
    "        new_image_path = f\"dataset/001.Plastic_bag/images/{dataset}/flipped_{id}.jpg\"  # Full path in df\n",
    "        \n",
    "        xmin = row['XMin'] * image_width\n",
    "        xmax = row['XMax'] * image_width\n",
    "        ymin = row['YMin']\n",
    "        ymax = row['YMax']\n",
    "        \n",
    "        # Get new coordinates for flipped bounding boxes\n",
    "        new_xmin = ((image_width/2)-(xmin-(image_width/2))) / image_width\n",
    "        new_xmax = ((image_width/2)-(xmax-(image_width/2))) / image_width\n",
    "        \n",
    "        temp_df.loc[counter] = [2, 5, \"0.000\", new_xmin, ymin, new_xmax, ymax, new_image_path]\n",
    "        counter += 1\n",
    "    \n",
    "    df_merged = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "    # Save .lst in dataset/001.Plastic_bag/\n",
    "    df_merged.to_csv(os.path.join(base_dir, f'001.Plastic_bag/{dataset}.lst'), sep=\"\\t\", float_format=\"%.4f\", header=None)\n",
    "    print(len(df))  # Original df\n",
    "    print(\"augmented df length below\")\n",
    "    print(len(temp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9dcfec-e261-4f3d-b9ab-dcdc1841a229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = glob.glob(train_images_path)\n",
    "counter = 0\n",
    "for i in folder:\n",
    "    counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5daf82-9994-4472-a491-9ee4db43f0da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = glob.glob(test_images_path)\n",
    "counter = 0\n",
    "for i in folder:\n",
    "    counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b39a58c-6bb3-4a86-974c-367c3bbdeb33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(final_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebe040d-a4e6-4d0b-b346-3d83f048144c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(final_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e6fd5a-1a10-4d40-9d26-245293afc23f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "augment_data(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c0b6ed-275e-4ec5-ac15-12b073f92522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = glob.glob(test_images_path)\n",
    "counter = 0\n",
    "for i in folder:\n",
    "    counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439dd2be-86fe-4373-8c2e-d83f9c863941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "162 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dce863b-2179-4b53-b466-dac76147b903",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "augment_data(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994c273b-9c48-45a8-a672-9fd882030f5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = glob.glob(train_images_path)\n",
    "counter = 0\n",
    "for i in folder:\n",
    "    counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5a944b-f757-4eae-9a60-5160bdbcbe28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "449*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc282c9-aed4-420b-9f84-1a292cf2b193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "im=Image.open(os.path.join(train_images_dir, '004bd64410736c69.jpg'))\n",
    "w,h=im.size\n",
    "\n",
    "# Sample: 0\t2\t5\t0.000\t0.2328\t0.1186\t0.6611\t0.7358\t001.Plastic_bag/images/train/004bd64410736c69.jpg\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xmin = 0.2328\n",
    "xmax = 0.6611\n",
    "ymin = 0.1186\n",
    "ymax = 0.7358\n",
    "\n",
    "xmin=xmin*w\n",
    "xmax=xmax*w\n",
    "ymin=ymin*h\n",
    "ymax=ymax*h\n",
    "\n",
    "\n",
    "  \n",
    "width=xmax-xmin\n",
    "height=ymax-ymin\n",
    "\n",
    "rect = patches.Rectangle((xmin, ymin), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "\n",
    "  # Add the patch to the Axes\n",
    "ax.add_patch(rect)\n",
    "\n",
    "\n",
    "  # Display the image\n",
    "ax.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd5d94e-9aa3-49e3-b193-1a93eaf6fdc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Theory Lesson\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "# Use a valid image path from dataset (replace with actual if needed)\n",
    "im = Image.open(os.path.join(train_images_dir, '004bd64410736c69.jpg'))\n",
    "im = im.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(im)\n",
    "\n",
    "image_width, image_height = im.size\n",
    "print(image_width, image_height) # Expected: 1024 683 (adjusted for your image)\n",
    "\n",
    "# Sample normalized coords from JSON for this image (flipped Plastic bag)\n",
    "xmin_flipped_norm = 1 - 0.6611  # Flipped from original xmax_norm\n",
    "xmax_flipped_norm = 1 - 0.2328  # Flipped from original xmin_norm\n",
    "ymin_norm = 0.1186\n",
    "ymax_norm = 0.7358\n",
    "\n",
    "xmin = xmin_flipped_norm * image_width\n",
    "xmax = xmax_flipped_norm * image_width\n",
    "ymin = ymin_norm * image_height\n",
    "ymax = ymax_norm * image_height\n",
    "\n",
    "\n",
    "  \n",
    "width = xmax - xmin\n",
    "height = ymax - ymin\n",
    "\n",
    "rect = patches.Rectangle((xmin, ymin), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "\n",
    "  # Add the patch to the Axes\n",
    "ax.add_patch(rect)\n",
    "\n",
    "\n",
    "  # Display the image\n",
    "ax.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53947545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install opencv-python\n",
    "!{sys.executable} -m pip install mxnet\n",
    "!{sys.executable} -m pip install distro numpy==1.23.5 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2235f88-1652-40c5-b518-2e3ba64cc787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import distro\n",
    "import os\n",
    "\n",
    "if distro.id() == \"debian\":\n",
    "    os.system(\"apt-get update\")\n",
    "    os.system(\"apt-get install ffmpeg libsm6 libxext6 -y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461a6404-b6b9-4d25-b7a1-f57f5f9547dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RESIZE_SIZE = 256\n",
    "BASE_DIR = os.path.join(os.path.dirname(os.getcwd()), 'dataset/001.Plastic_bag/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587449ad-5cd8-4bc2-a37f-f2faeabfba8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python3 ../tools/im2rec.py --resize $RESIZE_SIZE --pack-label test.lst $BASE_DIR/images/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8b3115-50af-472a-9115-e62de1b0844c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python3 ../tools/im2rec.py --resize $RESIZE_SIZE --pack-label train.lst $BASE_DIR/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815e2c74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
